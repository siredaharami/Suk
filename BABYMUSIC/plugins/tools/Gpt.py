import random
import time
from BABYMUSIC import app
import requests
from pyrogram.types import Message
from pyrogram.types import InputMediaPhoto
from teambabyAPI import api
from pyrogram.enums import ChatAction, ParseMode
from pyrogram import filters
from transformers import pipeline  # Hugging Face model import

# Load Hugging Face model for question answering
qa_model = pipeline("question-answering", model="distilbert-base-uncased-distilled-squad")

@app.on_message(
    filters.command(
        ["chatgpt", "ai", "ask", "gpt", "solve"],
        prefixes=["+", ".", "/", "-", "", "$", "#", "&"],
    )
)
async def chat_gpt(bot, message):
    
    try:
        await bot.send_chat_action(message.chat.id, ChatAction.TYPING)
        
        if len(message.command) < 2:
            await message.reply_text(
                "â á´‡xá´€á´á´˜ÊŸá´‡:**\n\n/chatgpt á´¡Êœá´ Éªs á´›Êœá´‡ á´á´¡É´á´‡Ê€ á´Ò“ Ë¹ Ê™á´€Ê™Ê-á´á´œsÉªá´„ â„¢Ë¼ð“…‚?"
            )
        else:
            question = message.text.split(' ', 1)[1]  # Extracting the question
            
            # Here, we assume the context is a static text or can be dynamically fetched
            context = """
            Ë¹ Ê™Ê™Ê-á´á´œsÉªá´„ â„¢Ë¼ð“…‚ is a community platform for music lovers and people who enjoy lively discussions about various topics.
            """
            
            # Use Hugging Face model to get the answer
            result = qa_model(question=question, context=context)
            answer = result['answer']
            
            await message.reply_text(
                f"**Answer from AI:**\n\n{answer}\n\nâá´˜á´á´¡á´‡Ê€á´‡á´… Ê™Êâž›[Ê™Ê§Ê™Ê-á´á´œsÉªá´„â„¢](https://t.me/BABY09_WORLD)", 
                parse_mode=ParseMode.MARKDOWN
            )
    
    except Exception as e:
        await message.reply_text(f"**â á´‡Ê€Ê€á´Ê€: {e}**")
